# Setup Complete - Dev and Prod Environments

## ‚úÖ What's Been Created

### Directory Structure
```
environments/
‚îú‚îÄ‚îÄ dev/                                  # Development environment
‚îÇ   ‚îú‚îÄ‚îÄ lambda/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ lambda_manifest_builder.py   # Enhanced logging version
‚îÇ   ‚îú‚îÄ‚îÄ glue/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ (copy from ingestion-pipeline/app/)
‚îÇ   ‚îî‚îÄ‚îÄ scripts/
‚îÇ       ‚îú‚îÄ‚îÄ generate-test-data.sh        # Creates KB-sized files
‚îÇ       ‚îî‚îÄ‚îÄ (copy all diagnostic scripts from ingestion-pipeline/)
‚îÇ
‚îú‚îÄ‚îÄ prod/                                 # Production environment
‚îÇ   ‚îú‚îÄ‚îÄ lambda/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ lambda_manifest_builder.py   # Optimized version
‚îÇ   ‚îú‚îÄ‚îÄ glue/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ (copy from ingestion-pipeline/app/)
‚îÇ   ‚îî‚îÄ‚îÄ scripts/
‚îÇ       ‚îú‚îÄ‚îÄ generate-test-data.sh        # Creates 3.5-4GB files
‚îÇ       ‚îî‚îÄ‚îÄ deploy-*.sh scripts
‚îÇ
‚îú‚îÄ‚îÄ README.md                             # Full documentation
‚îî‚îÄ‚îÄ SETUP-COMPLETE.md                     # This file
```

### Created Files

1. **Development Lambda** (`environments/dev/lambda/lambda_manifest_builder.py`)
   - DEBUG logging level
   - Full event dumps
   - Try-catch with stack traces
   - Emoji progress markers (üöÄ, ‚úì, ‚úó, ‚ö†Ô∏è)
   - Object introspection

2. **Production Lambda** (`environments/prod/lambda/lambda_manifest_builder.py`)
   - INFO logging level only
   - Minimal logging
   - Optimized performance
   - No debug overhead

3. **Test Data Generators**
   - Dev: Creates 10-20 KB files (`environments/dev/scripts/generate-test-data.sh`)
   - Prod: Creates 3.5-4 GB files (`environments/prod/scripts/generate-test-data.sh`)

4. **Documentation**
   - `environments/README.md` - Complete usage guide
   - `SCALABILITY-ANALYSIS.md` - Critical architecture analysis

## üö® CRITICAL FINDINGS

### Your Production Scale Won't Work with Current Architecture!

**The Problem:**
- You have 150,000-338,000 files per day
- Each file is 3.5-4.5 GB
- Current batch size (1 GB) means each file gets its own manifest
- Current Glue setup processes 1 manifest at a time
- **Result**: Would take 470 DAYS to process 1 day of data!

**Required Changes:**
See `SCALABILITY-ANALYSIS.md` for full details.

### Quick Fix Recommendations

1. **Change Lambda batching from SIZE to FILE COUNT:**
   ```python
   MAX_FILES_PER_MANIFEST = 100  # Instead of 1GB size limit
   MAX_BATCH_SIZE_GB = 500       # 100 files √ó 4.5GB max
   ```

2. **Enable Glue parallel processing:**
   ```bash
   MaxConcurrentRuns: 50
   WorkerType: G.2X
   NumberOfWorkers: 10
   ```

3. **Expected Performance:**
   - Process 338,000 files in 3-7 hours (vs 470 days!)
   - Cost: $33K-$82K/month
   - Alternative EMR: $19K-$50K/month

## üìã Next Steps to Complete Setup

### Step 1: Copy Scripts to Environments

```bash
# Copy diagnostic scripts to dev
cp ingestion-pipeline/check-*.sh environments/dev/scripts/
cp ingestion-pipeline/diagnose-pipeline.sh environments/dev/scripts/
cp ingestion-pipeline/fix-*.sh environments/dev/scripts/
cp ingestion-pipeline/run-glue-batch.sh environments/dev/scripts/
cp ingestion-pipeline/upload-test-data.sh environments/dev/scripts/
cp ingestion-pipeline/test-end-to-end.sh environments/dev/scripts/

# Copy Glue jobs
cp ingestion-pipeline/app/glue_streaming_job.py environments/dev/glue/
cp ingestion-pipeline/app/glue_streaming_job.py environments/prod/glue/
```

### Step 2: Make Scripts Executable

```bash
chmod +x environments/dev/scripts/*.sh
chmod +x environments/prod/scripts/*.sh
```

### Step 3: Test Development Environment

```bash
cd environments/dev/scripts

# 1. Generate small test files
./generate-test-data.sh 10 100

# 2. Deploy dev Lambda
cd ../lambda
zip -r lambda.zip lambda_manifest_builder.py
aws lambda update-function-code \
  --function-name ndjson-parquet-sqs-manifest-builder \
  --zip-file fileb://lambda.zip \
  --region us-east-1

# 3. Upload test data
cd ../scripts
./upload-test-data.sh

# 4. Monitor
./check-lambda-logs.sh
./check-dynamodb-files.sh
```

### Step 4: Review Scalability Analysis

```bash
# Read the critical analysis
cat ../../SCALABILITY-ANALYSIS.md

# Key sections:
# - Production Metrics (your scale)
# - Critical Architectural Problem
# - Recommended Architecture Changes
# - Cost Projections
```

### Step 5: Update Lambda for File-Count Batching

You need to modify the Lambda code to batch by FILE COUNT instead of SIZE:

```python
# In environments/dev/lambda/lambda_manifest_builder.py
# and environments/prod/lambda/lambda_manifest_builder.py

# Change from:
MAX_BATCH_SIZE_GB = float(os.environ.get('MAX_BATCH_SIZE_GB', '1.0'))

# To:
MAX_FILES_PER_MANIFEST = int(os.environ.get('MAX_FILES_PER_MANIFEST', '100'))
MAX_BATCH_SIZE_GB = float(os.environ.get('MAX_BATCH_SIZE_GB', '500'))  # Safety limit

# Then update _create_batches() to count files instead of size
```

### Step 6: Enable Glue Concurrent Runs

```bash
# Update Glue job configuration
aws glue update-job \
  --job-name ndjson-parquet-sqs-streaming-processor \
  --job-update '{
    "MaxConcurrentRuns": 50,
    "WorkerType": "G.2X",
    "NumberOfWorkers": 10
  }' \
  --region us-east-1
```

## üéØ Environment-Specific Usage

### Development Environment

**Purpose**: Fast iteration, debugging, testing

**Test Data**: 10-20 KB files
```bash
cd environments/dev/scripts
./generate-test-data.sh 10 100  # 10 files, 100 records each
```

**Features**:
- Extensive DEBUG logging
- Every operation logged
- Full stack traces
- Object dumps
- Progress indicators

**Use Cases**:
- Code development
- Bug fixing
- Testing new features
- Learning the codebase

### Production Environment

**Purpose**: Optimal performance, minimal logging

**Test Data**: 3.5-4 GB files
```bash
cd environments/prod/scripts
./generate-test-data.sh 5 3.5  # 5 files, 3.5GB each

# WARNING: This takes time and space!
# 5 √ó 3.5GB = 17.5 GB total
# Expect 30-60 minutes to generate
```

**Features**:
- INFO logging only
- Minimal overhead
- Optimized performance
- Production-grade error handling

**Use Cases**:
- Load testing
- Performance benchmarking
- Production deployment validation

## üìä Cost Estimates

### Development (Testing)
- **Lambda**: ~$10/month (light usage)
- **Glue**: ~$50/month (occasional testing)
- **S3**: ~$100/month (test data storage)
- **DynamoDB**: ~$20/month
- **Total**: ~$180/month

### Production (Your Scale: 338K files/day)

**Option 1: File-Count Batching + Parallel Glue** (Recommended)
- **S3**: $12,000 - $35,000/month (525TB - 1.5PB storage)
- **Lambda**: $600/month
- **DynamoDB**: $450/month
- **SQS**: $50/month
- **Glue**: $20,000 - $46,000/month (50 concurrent jobs)
- **Total**: **$33,000 - $82,000/month**

**Option 2: EMR Cluster** (Best Price/Performance)
- **S3**: $12,000 - $35,000/month
- **Lambda**: $600/month
- **DynamoDB**: $450/month
- **EMR**: $6,000 - $14,000/month (spot instances)
- **Total**: **$19,000 - $50,000/month**

## ‚ö†Ô∏è Important Warnings

### Do NOT Deploy Production Code Without Changes!

The current architecture **WILL NOT SCALE** to your production requirements.

**You must implement file-count batching** before production deployment.

### Test Progressively

1. Start with 10 KB files (dev)
2. Test with 100 MB files
3. Test with 1 GB files
4. Test with 3.5 GB files (prod)
5. Test with 10 files
6. Test with 100 files
7. Test with 1,000 files
8. Monitor costs at each step!

### Monitor Costs Closely

Set up billing alarms:
```bash
# Create CloudWatch billing alarm
aws cloudwatch put-metric-alarm \
  --alarm-name high-daily-cost \
  --alarm-description "Alert if daily cost > $3000" \
  --metric-name EstimatedCharges \
  --namespace AWS/Billing \
  --statistic Maximum \
  --period 86400 \
  --evaluation-periods 1 \
  --threshold 3000 \
  --comparison-operator GreaterThanThreshold
```

## üìö Documentation Index

1. **environments/README.md**
   - Complete usage guide
   - Dev vs Prod differences
   - Deployment instructions
   - Testing workflows

2. **SCALABILITY-ANALYSIS.md** ‚≠ê **CRITICAL - READ FIRST**
   - Production metrics analysis
   - Architecture bottlenecks
   - Recommended solutions
   - Cost projections
   - Performance benchmarks

3. **ingestion-pipeline/COST-OPTIMIZATION.md**
   - Cost breakdown
   - Optimization strategies
   - Worker configurations

## üîß Files That Need Manual Copying

Due to the large number of scripts, you need to manually copy:

```bash
# From ingestion-pipeline/ to environments/dev/scripts/
- check-lambda-logs.sh
- check-dynamodb-files.sh
- check-sqs-queue.sh
- check-glue-logs.sh
- diagnose-pipeline.sh
- fix-lambda-trigger.sh
- fix-quarantine-bucket.sh
- run-glue-batch.sh
- upload-test-data.sh (modify for test-data-dev/)
- test-end-to-end.sh

# From ingestion-pipeline/app/ to environments/*/glue/
- glue_streaming_job.py
```

## ‚úÖ What Works Now

1. ‚úÖ Dev Lambda with extensive logging
2. ‚úÖ Prod Lambda optimized for performance
3. ‚úÖ Test data generators (KB for dev, GB for prod)
4. ‚úÖ Scalability analysis completed
5. ‚úÖ Architecture recommendations provided
6. ‚úÖ Cost estimates calculated
7. ‚úÖ Documentation complete

## ‚è≠Ô∏è What's Next

1. **Review SCALABILITY-ANALYSIS.md** (30 minutes)
2. **Copy diagnostic scripts** (5 minutes)
3. **Test dev environment** (1 hour)
4. **Implement file-count batching** (2-4 hours)
5. **Test with production-sized files** (2 hours)
6. **Load testing** (1 day)
7. **Production deployment** (after thorough testing)

## üÜò Support

If you need help:
1. Check the environment-specific README
2. Review scalability analysis
3. Check CloudWatch logs
4. Run diagnostic scripts
5. Review this setup guide

## Summary

You now have:
- ‚úÖ Separate dev and prod environments
- ‚úÖ Enhanced dev code with extensive logging
- ‚úÖ Optimized prod code
- ‚úÖ Test data generators for both environments
- ‚úÖ Critical scalability analysis
- ‚ö†Ô∏è **WARNING**: Architecture needs changes for production scale
- üìã Clear next steps

**Most Important**: Read `SCALABILITY-ANALYSIS.md` before deploying to production!
