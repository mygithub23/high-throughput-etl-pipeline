diff --git a/environments/dev/lambda/lambda_manifest_builder.py b/environments/dev/lambda/lambda_manifest_builder.py
index 79c57d7..c8c963b 100644
--- a/environments/dev/lambda/lambda_manifest_builder.py
+++ b/environments/dev/lambda/lambda_manifest_builder.py
@@ -5,7 +5,7 @@ Lambda #1: Manifest Builder - DEVELOPMENT VERSION
 Enhanced version with extensive logging, try-catch blocks, and debugging features.

 Author: Data Engineering Team
-Version: 1.2.0-dev
+Version: 1.3.0-dev
 Environment: DEVELOPMENT

 Features:
@@ -13,6 +13,7 @@ Features:
 - Try-catch blocks with full stack traces
 - Object introspection and dumps
 - Debug mode for verbose output
+- End-of-day flush: Processes orphaned files from previous days automatically
 """

 import json
@@ -22,7 +23,7 @@ import hashlib
 import time
 import re
 import traceback
-from datetime import datetime, timedelta
+from datetime import datetime, timezone, timedelta
 from decimal import Decimal
 from typing import List, Dict, Tuple, Optional
 import logging
@@ -35,6 +36,7 @@ logger.setLevel(logging.DEBUG)  # DEBUG level for dev
 s3_client = boto3.client('s3')
 dynamodb = boto3.resource('dynamodb')
 glue_client = boto3.client('glue')
+sfn_client = boto3.client('stepfunctions')

 # Environment Variables with validation
 try:
@@ -46,16 +48,27 @@ except KeyError as e:
     raise

 GLUE_JOB_NAME = os.environ.get('GLUE_JOB_NAME', '')
-MAX_BATCH_SIZE_GB = float(os.environ.get('MAX_BATCH_SIZE_GB', '1.0'))
+MAX_FILES_PER_MANIFEST = int(os.environ.get('MAX_FILES_PER_MANIFEST', '10'))
 QUARANTINE_BUCKET = os.environ.get('QUARANTINE_BUCKET', '')
 EXPECTED_FILE_SIZE_MB = float(os.environ.get('EXPECTED_FILE_SIZE_MB', '3.5'))
 SIZE_TOLERANCE_PERCENT = float(os.environ.get('SIZE_TOLERANCE_PERCENT', '10'))
 LOCK_TABLE = os.environ.get('LOCK_TABLE', TRACKING_TABLE)
 LOCK_TTL_SECONDS = int(os.environ.get('LOCK_TTL_SECONDS', '300'))
+STEP_FUNCTION_ARN = os.environ.get('STEP_FUNCTION_ARN', '')
+
+# End-of-day flush configuration
+# MIN_FILES_FOR_PARTIAL_BATCH: Minimum files needed to create a partial batch for previous days
+# Set to 1 to process any orphaned files, or higher to require a minimum batch size
+MIN_FILES_FOR_PARTIAL_BATCH = int(os.environ.get('MIN_FILES_FOR_PARTIAL_BATCH', '1'))
+
+# TTL configuration for DynamoDB records
+# Records will be automatically deleted after this many days
+TTL_DAYS = int(os.environ.get('TTL_DAYS', '30'))

 # Log all configuration
-logger.info(f"Configuration: MAX_BATCH_SIZE_GB={MAX_BATCH_SIZE_GB}, EXPECTED_FILE_SIZE_MB={EXPECTED_FILE_SIZE_MB}")
+logger.info(f"Configuration: MAX_FILES_PER_MANIFEST={MAX_FILES_PER_MANIFEST}, EXPECTED_FILE_SIZE_MB={EXPECTED_FILE_SIZE_MB}")
 logger.info(f"Configuration: SIZE_TOLERANCE_PERCENT={SIZE_TOLERANCE_PERCENT}, LOCK_TTL_SECONDS={LOCK_TTL_SECONDS}")
+logger.info(f"Configuration: MIN_FILES_FOR_PARTIAL_BATCH={MIN_FILES_FOR_PARTIAL_BATCH}, TTL_DAYS={TTL_DAYS}")

 # DynamoDB table
 table = dynamodb.Table(TRACKING_TABLE)
@@ -81,10 +94,10 @@ class DistributedLock:
             self.table.put_item(
                 Item={
                     'date_prefix': f'LOCK#{self.lock_key}',
-                    'file_name': 'LOCK',
+                    'file_key': 'LOCK',  # Range key in DynamoDB
                     'lock_id': self.lock_id,
                     'ttl': ttl,
-                    'created_at': datetime.utcnow().isoformat()
+                    'created_at': datetime.now(timezone.utc).isoformat()
                 },
                 ConditionExpression='attribute_not_exists(date_prefix) OR #ttl < :now',
                 ExpressionAttributeNames={'#ttl': 'ttl'},
@@ -113,7 +126,7 @@ class DistributedLock:
             self.table.delete_item(
                 Key={
                     'date_prefix': f'LOCK#{self.lock_key}',
-                    'file_name': 'LOCK'
+                    'file_key': 'LOCK'  # Range key in DynamoDB
                 },
                 ConditionExpression='lock_id = :lock_id',
                 ExpressionAttributeValues={':lock_id': self.lock_id}
@@ -131,7 +144,7 @@ def lambda_handler(event, context):
     """
     logger.info("=" * 80)
     logger.info("üöÄ Lambda invocation started")
-    logger.info(f"Request ID: {context.request_id}")
+    logger.info(f"Request ID: {context.aws_request_id}")
     logger.info(f"Function: {context.function_name}")
     logger.info(f"Memory: {context.memory_limit_in_mb}MB")
     logger.info(f"Time remaining: {context.get_remaining_time_in_millis()}ms")
@@ -247,14 +260,51 @@ def process_file(bucket: str, key: str, size: int) -> str:
         track_file(bucket, key, date_prefix, file_name, size)
         logger.debug(f"‚úì File tracked in DynamoDB")

-        # Check if ready for manifest
-        logger.debug(f"üîç Checking if ready to create manifests for {date_prefix}")
-        manifests_created = create_manifests_if_ready(date_prefix)
+        # Keep creating manifests until all pending files are processed
+        # This handles the case where multiple Lambdas run in parallel
+        total_manifests = 0
+        max_iterations = 50  # Safety limit to prevent infinite loops
+        consecutive_failures = 0
+        max_consecutive_failures = 3  # Retry up to 3 times if lock is held

-        if manifests_created > 0:
-            logger.info(f"‚úì Created {manifests_created} manifest(s) for {date_prefix}")
-        else:
-            logger.debug(f"‚ÑπÔ∏è  Not ready for manifest yet")
+        for iteration in range(1, max_iterations + 1):
+            logger.debug(f"üîç Manifest creation iteration {iteration} for {date_prefix}")
+
+            manifests_created = create_manifests_if_ready(date_prefix)
+
+            if manifests_created > 0:
+                total_manifests += manifests_created
+                consecutive_failures = 0  # Reset failure counter on success
+                logger.info(f"‚úì Iteration {iteration}: Created {manifests_created} manifest(s) for {date_prefix}")
+                # Small delay to allow other Lambdas to finish their DynamoDB writes
+                time.sleep(0.1)
+            else:
+                # Check if there are still enough pending files (lock contention case)
+                pending_count = _count_pending_files(date_prefix)
+                logger.debug(f"‚ÑπÔ∏è  Iteration {iteration}: No manifests created, {pending_count} files still pending")
+
+                if pending_count >= MAX_FILES_PER_MANIFEST:
+                    # Files are pending but we couldn't create manifest (likely lock contention)
+                    consecutive_failures += 1
+                    if consecutive_failures < max_consecutive_failures:
+                        logger.info(f"‚è≥ Lock contention detected, waiting and retrying ({consecutive_failures}/{max_consecutive_failures})")       
+                        time.sleep(0.5)  # Wait 500ms before retrying
+                        continue
+                    else:
+                        logger.info(f"‚ÑπÔ∏è  Max retries reached, another Lambda will handle remaining files")
+                        break
+                else:
+                    # Not enough files to create a manifest
+                    logger.debug(f"‚ÑπÔ∏è  Not enough pending files ({pending_count} < {MAX_FILES_PER_MANIFEST})")
+                    break
+
+        if total_manifests > 0:
+            logger.info(f"‚úì Total: Created {total_manifests} manifest(s) for {date_prefix}")

moula@DESKTOP-A2H22E6 MINGW64 ~/OneDrive/Documents/_Dev/claude/claude-ndjson-parquet-proj-v5/high-throughputh-ingestion-pipeline (main)
$
+                        logger.info(f"‚ÑπÔ∏è  Max retries reached, another Lambda will handle remaining files")
+                        break
+                else:
+                    # Not enough files to create a manifest
+                    logger.debug(f"‚ÑπÔ∏è  Not enough pending files ({pending_count} < {MAX_FILES_PER_MANIFEST})")
+                    break
+
+        if total_manifests > 0:
+                        logger.info(f"‚ÑπÔ∏è  Max retries reached, another Lambda will handle remaining files")
+                        break
+                else:
+                    # Not enough files to create a manifest
+                        logger.info(f"‚ÑπÔ∏è  Max retries reached, another Lambda will handle remaining files")
+                        break
+                        logger.info(f"‚ÑπÔ∏è  Max retries reached, another Lambda will handle remaining files")
+                        logger.info(f"‚ÑπÔ∏è  Max retries reached, another Lambda will handle remaining files")
+                        break
+                else:
+                    # Not enough files to create a manifest
+                    logger.debug(f"‚ÑπÔ∏è  Not enough pending files ({pending_count} < {MAX_FILES_PER_MANIFEST})")
+                    break
+
+        if total_manifests > 0:
+            logger.info(f"‚úì Total: Created {total_manifests} manifest(s) for {date_prefix}")

moula@DESKTOP-A2H22E6 MINGW64 ~/OneDrive/Documents/_Dev/claude/claude-ndjson-parquet-proj-v5/high-throughputh-ingestion-pipeline (main)
$




+                else:
+                    # Not enough files to create a manifest
+                    logger.debug(f"‚ÑπÔ∏è  Not enough pending files ({pending_count} < {MAX_FILES_PER_MANIFEST})")
+                    break
+
+        if total_manifests > 0:
+            logger.info(f"‚úì Total: Created {total_manifests} manifest(s) for {date_prefix}")

moula@DESKTOP-A2H22E6 MINGW64 ~/OneDrive/Documents/_Dev/claude/claude-ndjson-parquet-proj-v5/high-throughputh-ingestion-pipeline (main)
$

+                else:
+                    # Not enough files to create a manifest
+                    logger.debug(f"‚ÑπÔ∏è  Not enough pending files ({pending_count} < {MAX_FILES_PER_MANIFEST})")
+                    break
+
+        if total_manifests > 0:
+            logger.info(f"‚úì Total: Created {total_manifests} manifest(s) for {date_prefix}")

+                else:
+                    # Not enough files to create a manifest
+                    logger.debug(f"‚ÑπÔ∏è  Not enough pending files ({pending_count} < {MAX_FILES_PER_MANIFEST})")
+                    break
+
+        if total_manifests > 0:
+            logger.info(f"‚úì Total: Created {total_manifests} manifest(s) for {date_prefix}")
+                else:
+                    # Not enough files to create a manifest
+                    logger.debug(f"‚ÑπÔ∏è  Not enough pending files ({pending_count} < {MAX_FILES_PER_MANIFEST})")
+                else:
+                    # Not enough files to create a manifest
+                else:
+                    # Not enough files to create a manifest
+                    logger.debug(f"‚ÑπÔ∏è  Not enough pending files ({pending_count} < {MAX_FILES_PER_MANIFEST})")
+                    break
+
+        if total_manifests > 0:
+            logger.info(f"‚úì Total: Created {total_manifests} manifest(s) for {date_prefix}")

moula@DESKTOP-A2H22E6 MINGW64 ~/OneDrive/Documents/_Dev/claude/claude-ndjson-parquet-proj-v5/high-throughputh-ingestion-pipeline (main)
$

+                else:
+                    # Not enough files to create a manifest
+                    logger.debug(f"‚ÑπÔ∏è  Not enough pending files ({pending_count} < {MAX_FILES_PER_MANIFEST})")
+                    break
+
+        if total_manifests > 0:
+            logger.info(f"‚úì Total: Created {total_manifests} manifest(s) for {date_prefix}")

moula@DESKTOP-A2H22E6 MINGW64 ~/OneDrive/Documents/_Dev/claude/claude-ndjson-parquet-proj-v5/high-throughputh-ingestion-pipeline (main)
+                else:
+                    # Not enough files to create a manifest
+                    logger.debug(f"‚ÑπÔ∏è  Not enough pending files ({pending_count} < {MAX_FILES_PER_MANIFEST})")
+                    break
+
+        if total_manifests > 0:
+            logger.info(f"‚úì Total: Created {total_manifests} manifest(s) for {date_prefix}")

+                else:
+                    # Not enough files to create a manifest
+                    logger.debug(f"‚ÑπÔ∏è  Not enough pending files ({pending_count} < {MAX_FILES_PER_MANIFEST})")
+                    break
+
+        if total_manifests > 0:
+                else:
+                    # Not enough files to create a manifest
+                    logger.debug(f"‚ÑπÔ∏è  Not enough pending files ({pending_count} < {MAX_FILES_PER_MANIFEST})")
+                    break
+
+                else:
+                    # Not enough files to create a manifest
+                    logger.debug(f"‚ÑπÔ∏è  Not enough pending files ({pending_count} < {MAX_FILES_PER_MANIFEST})")
+                else:
+                    # Not enough files to create a manifest
+                else:
+                else:
+                    # Not enough files to create a manifest
+                else:
+                else:
+                    # Not enough files to create a manifest
+                else:
+                    # Not enough files to create a manifest
+                else:
+                else:
+                    # Not enough files to create a manifest
+                    logger.debug(f"‚ÑπÔ∏è  Not enough pending files ({pending_count} < {MAX_FILES_PER_MANIFEST})")
+                    break
+
+        if total_manifests > 0:
+            logger.info(f"‚úì Total: Created {total_manifests} manifest(s) for {date_prefix}")
